{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JK301 - Audiovisual Transcription Exploratory  Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was developed to explore the feasability and issues related to the collection of full verbal and transcription report of videos of naturally spoken English sentences. The typed transcriptions were spell-corrected, aligned at the word and phonemic level and compared to the original text of the spoken sentences. The transcription accuracy each phoneme and word in each sentenece was coded to allow us to estimate the accuracy of the listener at multiple levels of processing over the course of each sentence.    \n",
    "\n",
    "1. Questions for JK301:\n",
    "\n",
    "     1. Is the system sufficiently robust against common spelling errors?\n",
    "     \n",
    "     2. Is the system correctly grading word errors?\n",
    "     \n",
    "     3. How well can normal hearing participants report the sentence words spoken without noise? \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well can normal hearing participants report the sentence words spoken without noise? \n",
    "\n",
    "First, let's load in the data and select only the trials without background noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File C:\\TCDTIMIT\\dataOut\\JK301\\bigPJK301_r1.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-407-efa3a96ef142>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mbigP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\TCDTIMIT\\dataOut\\JK301\\bigPJK301_r1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#Recalculate word accuracy based on phoneme accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mfrom_csv\u001b[1;34m(cls, path, header, sep, index_col, parse_dates, encoding, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                           \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                           \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtupleize_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m                           infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'block'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3246)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6111)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File C:\\TCDTIMIT\\dataOut\\JK301\\bigPJK301_r1.csv does not exist"
     ]
    }
   ],
   "source": [
    "#Load Big P\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess \n",
    "\n",
    "\n",
    "\n",
    "bigP = pd.DataFrame.from_csv(os.path.normpath(r'C:\\TCDTIMIT\\dataOut\\JK301\\bigPJK301_r1.csv'))\n",
    "\n",
    "#Recalculate word accuracy based on phoneme accuracy\n",
    "allPhonsMatch = bigP.groupby('WordCount')['PhonemeHitBool'].transform(lambda x: np.mean(x) ==1)\n",
    "allPhonsMatch.name = 'AllPhonsMatch'\n",
    "bigP = bigP.join(allPhonsMatch)\n",
    "\n",
    "\n",
    "isClear = bigP['BabbleCond'] == 'Off'\n",
    "isNoisy = bigP['BabbleCond'] == 'On'\n",
    "\n",
    "#Select only clear trials\n",
    "bigP = bigP[isClear]\n",
    "\n",
    "#Group by subject\n",
    "groupedSubject = bigP.groupby('Subject')\n",
    "\n",
    "#Mean values\n",
    "subjectMean = groupedSubject['PhonemeHitBool'].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the accuracy (fraction of words correctly reported) for each participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make plots prettier\n",
    "#Edited from Randel Olson and many at StackOverflow\n",
    "# These are the \"Tableau 20\" colors as RGB.    \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.) \n",
    "\n",
    "\n",
    "plt.rc('text', color = 'black') \n",
    "plt.rc('font', family='sans-serif') \n",
    "plt.rc('font', serif='Helvetica Neue') \n",
    "plt.rc('axes', titlesize = 18, labelsize = 14,labelcolor ='black')  \n",
    "plt.rc('lines', linewidth=2,markersize = 10)\n",
    "plt.rc('xtick',labelsize = 10,color ='black')\n",
    "plt.rc('ytick',labelsize = 10,color ='black')\n",
    "def hide_spines():\n",
    "    \"\"\"Hides the top and rightmost axis spines from view for all active\n",
    "    figures and their respective axes.\"\"\"\n",
    "\n",
    "    # Retrieve a list of all current figures.\n",
    "    figures = [x for x in plt._pylab_helpers.Gcf.get_all_fig_managers()]\n",
    "    for figure in figures:\n",
    "        # Get all Axis instances related to the figure.\n",
    "        for ax in figure.canvas.figure.get_axes():\n",
    "            # Disable spines.\n",
    "            ax.spines['right'].set_color('none')\n",
    "            ax.spines['top'].set_color('none')\n",
    "            # Disable ticks.\n",
    "            ax.xaxis.set_ticks_position('bottom')\n",
    "            ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjectMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = subjectMean.plot(kind='bar',figsize = (12,4),title = 'Phoneme Accuracy by Subject',color = tableau20[0])\n",
    "ax.set_ylabel('Mean Phoneme Accuracy')\n",
    "hide_spines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the worst particpant (p004) had 78% accuracy. The best had 94% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the missed words due to working memory loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look to see if working memory is playing a role in clear voice transcription errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigP.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a column for the number of words in the sentence\n",
    "bigP['NumWordsInSentence'] = bigP.groupby(['SentenceCount'])['WordIdx'].transform(max)+1\n",
    "\n",
    "#Sort sentence accuracy by number of words\n",
    "sentenceACC = bigP.groupby(['NumWordsInSentence'])['PhonemeHitBool','NumWordsInSentence'].mean()\n",
    "sentenceACC.set_index('NumWordsInSentence')\n",
    "#sentenceACC = sentenceACC.sort_values('NumWordsInSentence')\n",
    "filtered = lowess(sentenceACC['PhonemeHitBool'],np.arange(0,len(sentenceACC)))\n",
    "sentenceACC['Filt'] = filtered[:,1]\n",
    "#accplot = sentenceACC['PhonemeHitBool'].plot(kind='line',figsize = (12,4),color='black')\n",
    "ax = sentenceACC[['PhonemeHitBool','Filt']].plot(kind='line',figsize = (12,4),color = np.array(tableau20)[[1,0]])\n",
    "ax.legend(['Raw','Lowess Smoothed'])\n",
    "ax.set_ylabel('Phoneme Hit Rate')\n",
    "ax.set_xlabel('Number of Words in the Sentence')\n",
    "hide_spines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we get about 30% drop in mean transcription acccuracy from 3 to 17 words!  This means that working memory is a critical factor for longer sentences, even when sentences are spoken clearly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is fairly level at around 90% between 4 and 8 words to a sentence. Let's look only at sentences less than 9 words long and see what words these errors are coming from.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigPShort  = bigP[bigP['NumWordsInSentence'] < 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are some talkers harder to understand, even with fewer than 9 words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look again at individual subject performance, now including only sentences below 9 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Group by subject\n",
    "groupedSubject = bigPShort.groupby('Subject')\n",
    "\n",
    "#Mean values\n",
    "subjectMean = groupedSubject['PhonemeHitBool'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = subjectMean.plot(kind='bar',figsize = (12,4),title = 'Phoneme Accuracy by Subject',color = tableau20[0])\n",
    "ax.set_ylabel('Mean Phoneme Accuracy')\n",
    "hide_spines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The worst performing subject (p004) has 86% phoneme transcription accuracy for clear sentences under 9 words long. Now lets break it down by individual talker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groupedSpeaker = bigPShort.groupby(['Subject','Speaker'])\n",
    "speakerMean = groupedSpeaker.mean()\n",
    "ax = speakerMean['PhonemeHitBool'].plot(kind='bar',figsize = (12,4))\n",
    "plt.axhline(y=.80, xmin=0, xmax=59, linewidth=2, color = 'k')\n",
    "hide_spines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each talker was only heard by one subject, so we won't be able to separate talker from subject completely. However, we could try to figure out which talkers were the most difficult for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " zscore = lambda x: (x - x.mean()) / x.std()\n",
    "speakerMean['Zscore'] = 0    \n",
    "scores = speakerMean['PhonemeHitBool'].reset_index().groupby(['Subject']).transform(zscore)\n",
    "speakerMean.index.levels[1][speakerMean.index.labels[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores.plot(kind='bar',figsize = (12,4),x = speakerMean.index.levels[1][speakerMean.index.labels[1]])\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we exclude speakers with harder to understand speech? Perhaps variation is not a bad thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which words are participants getting wrong and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Grouped by word\n",
    "groupedWord = bigPShort.groupby('WordCount')\n",
    "\n",
    "wordACC = groupedWord.mean()['AllPhonsMatch']\n",
    "words = groupedWord['TargetWord'].first()\n",
    "\n",
    "#Grouped by Type\n",
    "wordHits = wordACC.groupby(words).sum()\n",
    "wordTotal = wordACC.groupby(words).count()\n",
    "wordHitRate = wordACC.groupby(words).sum()/wordACC.groupby(words).count()\n",
    "wordMisses = wordTotal-wordHits\n",
    "\n",
    "missSorted = wordMisses.sort_values(ascending =False)\n",
    "ax = missSorted[0:30].plot(kind='bar',figsize = (12,4))\n",
    "plt.figure()\n",
    "#Misses by word type as a percent of all missed words\n",
    "missPercSorted = (wordMisses*100/float(wordMisses.sum())).sort_values(ascending =False)\n",
    "ax = missPercSorted[0:30].plot(kind='bar',figsize = (12,4))\n",
    "plt.figure()\n",
    "#Hit rate for the worst hit rate words heard at least 6 times\n",
    "missPercSorted = (wordHitRate[wordTotal > 6] *100).sort_values(ascending =True)\n",
    "ax = missPercSorted[0:30].plot(kind='bar',figsize = (12,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordGrouped =  bigPShort.groupby('WordCount')['TargetWord','SourceWord','AllPhonsMatch'].first()\n",
    "trickyWords = wordGrouped[wordGrouped['TargetWord'].isin(missPercSorted.keys()[0:30])]\n",
    "trickyWords[trickyWords['AllPhonsMatch'] == False]\n",
    "missedWordsSpelling = wordGrouped[wordGrouped['AllPhonsMatch'] == False]\n",
    "missedWordsSpelling\n",
    "#[missPercSorted.keys()[0:30]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of the misses seem to be due to spelling errors. But the vast majority of the misses seem to come from the subject reporting the wrong word or not reporting any word. A few correct words are listed as having the wrong phonemes! This is likely due to phoneme alignment dilemas. For instance, the 'ay' in 'holiday' got assigned to the 'a' in 'aprons' when this subject reported 'aprons' as prints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigPShort[bigPShort['WordCount'] == 14237]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can correct this issue by setting all phonemes of exact word matches to the target phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find where words match\n",
    "matchIdx = bigPShort['SourceWord'] == bigPShort['TargetWord']\n",
    "#Set the source phonemes to match the target\n",
    "bigPShort.loc[matchIdx,('SourcePhoneme')] = bigPShort.loc[matchIdx,('TargetPhoneme')] \n",
    "#Reset the measure of phoneme accuracy\n",
    "bigPShort.loc[:,'PhonemeHitBool'] = bigPShort['SourcePhoneme'] == bigPShort['TargetPhoneme']\n",
    "#Reset the measure all phonemes matching\n",
    "bigPShort.loc[:,'AllPhonsMatch'] = bigPShort.groupby('WordCount')['PhonemeHitBool'].transform(lambda x: np.mean(x) ==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordGrouped =  bigPShort.groupby('WordCount')['TargetWord','SourceWord','AllPhonsMatch'].first()\n",
    "trickyWords = wordGrouped[wordGrouped['TargetWord'].isin(missPercSorted.keys()[0:30])]\n",
    "trickyWords[trickyWords['AllPhonsMatch'] == False]\n",
    "missedWordsSpelling = wordGrouped[wordGrouped['AllPhonsMatch'] == False]\n",
    "missedWordsSpelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pizzarias --> pizzarieas is probably a spelling error. So is for real --> forreal. But such errors seem to make up a very small fraction of overall errors, so we're pretty happy with the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does word accuracy relate to word frequency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Word Accuracy sorted by SubtlexUS Frequency \n",
    "vals = bigPShort.loc[:,('AllPhonsMatch','TargetWord','1LogGram')].groupby('TargetWord').mean().sort_values(['1LogGram'], ascending = False)\n",
    "vals = vals.groupby('1LogGram').mean()\n",
    "filtered = pd.ewma(vals['AllPhonsMatch'],span =50)\n",
    "ax = filtered.plot(kind='line',figsize = (12,4))\n",
    "ax.set_ylabel('Mean Word Accuracy')\n",
    "hide_spines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Subjects are much better at reporting frequent than very infrequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered = lowess(meanType['WordHit'],np.arange(0,len(meanType['WordHit'])))\n",
    "typeACC = meanType.sort_values('SFreq',ascending = False)['WordHit']\n",
    "typeACCFilt = typeACC\n",
    "filtered = lowess(typeACC.values,np.arange(0,len(typeACC)))\n",
    "typeACCFilt[0:] =  filtered[:,1]\n",
    "accplot = typeACCFilt.plot(kind='line',figsize = (12,4),color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grouped by Speaker\n",
    "groupedSpeaker = bigP.groupby('Speaker')\n",
    "speakerMean = groupedSpeaker.mean()\n",
    "speakerMean['PhonemeHitBool'].plot(kind='bar',figsize = (12,4))\n",
    "\n",
    "#Grouped by word\n",
    "groupedWord = bigP.groupby('WordCount')\n",
    "wordMean = groupedWord.mean()\n",
    "wordFirst = groupedWord.first()\n",
    "wordMean['TargetWord'] = wordFirst['TargetWord']\n",
    "wordMean['WordHit'] = wordMean['PhonemeHitBool'] == 1\n",
    "#Grouped by type\n",
    "groupedType = wordMean.groupby('TargetWord')\n",
    "\n",
    "#Plot top 20 missed words\n",
    "missedSorted = groupedType['WordHit'].apply(lambda x: np.sum(x == False)).sort_values(ascending = False)\n",
    "missplot = missedSorted[0:20].plot(kind='bar',figsize = (12,4))\n",
    "#Plot top 20 correct words\n",
    "hitSorted = groupedType['WordHit'].apply(lambda x: np.sum(x == True)).sort_values(ascending = False)\n",
    "hitplot = hitSorted[0:20].plot(kind='bar',figsize = (12,4))\n",
    "\n",
    "#Plot top 20 most common  words in corpus\n",
    "countSorted = groupedType['WordHit'].count().sort_values(ascending = False)\n",
    "countplot = countSorted[0:20].plot(kind='bar',figsize = (12,4))\n",
    "\n",
    "#Accuracy of top 20 most common words in english\n",
    "meanType = groupedType.mean()\n",
    "meanType['TypeCount'] = groupedType['WordHit'].count()\n",
    "typeACC = meanType.sort_values('SFreq',ascending = False)['WordHit']\n",
    "accbar = typeACC[0:60].plot(kind='bar',figsize = (12,4))\n",
    "accplot = typeACC.plot(kind='line',figsize = (12,4))\n",
    "typeACCFilt = typeACC\n",
    "filtered = lowess(typeACC.values,np.arange(0,len(typeACC)))\n",
    "typeACCFilt[0:] =  filtered[:,1]\n",
    "accplot = typeACCFilt.plot(kind='line',figsize = (12,4),color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
