# The LAND Kit

This is a repository where all of the stimulus presentation and analysis code required to run LANDKit projects will reside. The LAND Kit is a collection of software to facilitate the collection and analysis of software in the Lab of Auditory Neurophysiology and Development (LAND). 


The repository will be structured as:

1. Data Collection
  * [Database of required stimuli]
  * [Presentation Code]
  * [Documentation of hardware requirements]  
2. Data Analysis
  * [Data Consolidation]
  * [Language Model Generation]
  * [Statistics and Visualization] 

 The first project of LandKit is to determine the relative contribution of vision on auditory speech understanding at the levels of lexical and phonemic perception. One key input to the model are transcriptions from human participants watching videos of speech. Transcription success and error inform the model. Analysis and visualization identifies the key elements of the speech success and the interactions between visual information and successful speech retreival.       